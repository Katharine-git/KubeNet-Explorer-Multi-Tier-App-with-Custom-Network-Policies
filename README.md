# KubeNet-Explorer-Multi-Tier-App-with-Custom-Network-Policies

Networking is the backbone of Kubernetes.

I've set up a mini-project that will help you setup a cluster from scratch, deploy resources and build a basic network within the cluster.

ğŸ§© 1ï¸âƒ£ After Cluster Start

Command:

minikube start --driver=docker


âœ… Expected output:

ğŸ˜„  minikube v1.34.0 on Ubuntu 22.04
âœ¨  Using the docker driver
ğŸ‘  Starting control plane node minikube in cluster minikube
ğŸ”  Verifying Kubernetes components...
ğŸŒŸ  Enabled addons: default-storageclass, storage-provisioner, ingress
ğŸ„  Done! kubectl is now configured to use "minikube"


Verify:

kubectl get nodes


âœ… Output:

NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   1m    v1.30.0

ğŸ“¦ 2ï¸âƒ£ After Running bash scripts/deploy.sh

You should see messages like:

Creating namespaces...
namespace/frontend created
namespace/backend created
namespace/database created

Deploying MongoDB...
service/mongodb created
deployment.apps/mongodb created

Deploying Backend...
service/backend created
deployment.apps/backend created

Deploying Frontend...
service/frontend created
deployment.apps/frontend created

Applying NetworkPolicies...
networkpolicy.networking.k8s.io/backend-db-access created
networkpolicy.networking.k8s.io/frontend-isolated created

Applying Ingress...
ingress.networking.k8s.io/frontend-ingress created

âœ… Deployment complete!

ğŸ§  3ï¸âƒ£ Verify Pods and Services

Command:

kubectl get pods -A


âœ… Expected output:

NAMESPACE   NAME                          READY   STATUS    RESTARTS   AGE
database    mongodb-7c9f5dd78f-4jtzs      1/1     Running   0          30s
backend     backend-7c8fbb6d96-hqzqg      1/1     Running   0          28s
frontend    frontend-6dcbd67b4f-b9grf     1/1     Running   0          25s


Command:

kubectl get svc -A


âœ… Expected output:

NAMESPACE   NAME         TYPE        CLUSTER-IP       PORT(S)          AGE
database    mongodb      ClusterIP   10.96.32.11      27017/TCP        30s
backend     backend      ClusterIP   10.96.88.42      8080/TCP         28s
frontend    frontend     ClusterIP   10.96.54.23      80/TCP           25s

ğŸŒ 4ï¸âƒ£ Verify Ingress

Command:

kubectl get ingress -A


âœ… Expected output:

NAMESPACE   NAME              CLASS    HOSTS             ADDRESS          PORTS   AGE
frontend    frontend-ingress  nginx    frontend.local    127.0.0.1        80      10s


Browser Test:

Add to /etc/hosts:
127.0.0.1 frontend.local

Visit: http://frontend.local

âœ… You should see either:

The Nginx welcome page, or

A simple â€œFrontend is runningâ€ message if you customized it.

ğŸ”’ 5ï¸âƒ£ Network Policy Test

Backend â†’ Database (âœ… should succeed):

kubectl exec -n backend -it $(kubectl get pod -n backend -l app=backend -o jsonpath='{.items[0].metadata.name}') -- ping -c 2 mongodb.database.svc.cluster.local


âœ… Expected:

PING mongodb.database.svc.cluster.local (10.96.32.11): 56 data bytes
64 bytes from 10.96.32.11: icmp_seq=0 ttl=64 time=0.742 ms
64 bytes from 10.96.32.11: icmp_seq=1 ttl=64 time=0.625 ms


Frontend â†’ Database (âŒ should fail):

kubectl exec -n frontend -it $(kubectl get pod -n frontend -l app=frontend -o jsonpath='{.items[0].metadata.name}') -- ping -c 2 mongodb.database.svc.cluster.local


âŒ Expected:

ping: mongodb.database.svc.cluster.local: Name or service not known
command terminated with exit code 1


Thatâ€™s the proof your NetworkPolicy is correctly isolating traffic.

ğŸ§¹ 6ï¸âƒ£ Cleanup

Command:

bash scripts/cleanup.sh


âœ… Expected output:

Deleting namespaces...
namespace "frontend" deleted
namespace "backend" deleted
namespace "database" deleted

âœ… Cleanup complete!

ğŸ’¡ Success Checklist
Step	Check	Status
Cluster started	kubectl get nodes â†’ Ready	âœ…
Namespaces created	kubectl get ns	âœ…
Pods running	kubectl get pods -A	âœ…
Ingress reachable	Browser â†’ frontend.local	âœ…
NetworkPolicy working	Backendâ†’DB âœ…, Frontendâ†’DB âŒ
